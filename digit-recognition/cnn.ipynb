{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPF5h9jT5+gDuS+gzS3sOj/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahausmani/deep_learning/blob/main/digit-recognition/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "xgtv47smOYvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "from torch.optim import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print('Using PyTorch version:', torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "    print('Using GPU, device name:', torch.cuda.get_device_name(0))\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print('No GPU found, using CPU instead.')\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhx3duyKPhxM",
        "outputId": "7b4cbbd8-c199-4d0f-da5a-d23f3733046b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.2.1+cu121\n",
            "Using GPU, device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mahausmani/deep_learning.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUlBMsypOdEl",
        "outputId": "9c85cc34-0b25-4185-d55c-3dd151e2f5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep_learning'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 110 (delta 41), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 15.84 MiB | 10.54 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# constants"
      ],
      "metadata": {
        "id": "tWzSVjloQCcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "data_dir = \"/content/data\"\n",
        "val_split = 0.3\n",
        "epochs = 50\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "lPh2QuzBQD72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading\n"
      ],
      "metadata": {
        "id": "bzHLyu1WOgFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(data_dir, train = True, download = True, transform = ToTensor())\n",
        "test_dataset = datasets.MNIST(data_dir, train = False, download = True, transform = ToTensor())\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "na0yvoKMP2-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDmiOQDYNaW-",
        "outputId": "3edf47da-bf32-475b-983d-7bb3883ac2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n"
      ],
      "metadata": {
        "id": "lrkYu3s9RhGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for target, label in train_dataloader:\n",
        "    print(target.shape, label.shape)\n",
        "    print(f\"Batch Size --> { target.shape[0]}\")\n",
        "    print(f\"Input Size --> [{target.shape[2]} x {target.shape[-1]}]\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHEVDBQIRqvQ",
        "outputId": "2cc76722-169f-46c3-e570-3e8c558c4c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28]) torch.Size([32])\n",
            "Batch Size --> 32\n",
            "Input Size --> [28 x 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        # 1. CONV --> RELU --> MAXPOOL\n",
        "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 20, kernel_size = (5,5))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2))\n",
        "\n",
        "        # 2. CONV --> RELU --> MAXPOOL\n",
        "        self.conv2 = nn.Conv2d(in_channels = 20, out_channels = 50, kernel_size = (5,5))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride = (2,2))\n",
        "\n",
        "        # 3. FC --> ReLU\n",
        "        self.fc3 = nn.Linear(in_features = 800, out_features=500)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        # 4. FC --> Softmax\n",
        "        self.fc4 = nn.Linear(in_features = 500, out_features = 10)\n",
        "        self.softmax = nn.LogSoftmax(dim = 1)\n",
        "    def forward(self, x):\n",
        "        # layer1\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # layer2\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # layer3\n",
        "        x = flatten(x,1)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        # layer4\n",
        "        x = self.fc4(x)\n",
        "        output = self.softmax(x)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "_6P2wYmQR5KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNModel(1,10)\n",
        "model = model.to(device)\n",
        "opt = Adam(model.parameters(), lr=lr)\n",
        "lossFN = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "cFwQPiRazAp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s7f65GF2cCs",
        "outputId": "8140d6b4-6fe0-4de7-ec5d-55f0c69e52ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNModel(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc3): Linear(in_features=800, out_features=500, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc4): Linear(in_features=500, out_features=10, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "uIQQfeVsG2qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "    training_loss = 0\n",
        "    correct_predictions = 0\n",
        "    for x, y in train_dataloader:\n",
        "        model.train()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        pred = model(x)\n",
        "        loss = lossFN(pred, y)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        predicted = pred.argmax(dim=1).cpu().numpy()\n",
        "        labels = y.cpu().numpy()\n",
        "        correct_predictions += (predicted == labels).sum()\n",
        "        training_loss+=loss\n",
        "    if i%5==0:\n",
        "        print(f\"Epoch --> {i} Loss --> {training_loss}\", end = \" \")\n",
        "        print(f\"Correct Pedictions --> {correct_predictions}\")\n",
        "        print(f\"Training Accuracy --> {correct_predictions/len(train_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHyW5-b1yvKD",
        "outputId": "6da53931-b4a3-4da7-8eaa-94cff35ba5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch --> 0 Loss --> 13.192895889282227 Correct Pedictions --> 59859\n",
            "Training Accuracy --> 0.99765\n",
            "Epoch --> 5 Loss --> 11.442106246948242 Correct Pedictions --> 59894\n",
            "Training Accuracy --> 0.9982333333333333\n",
            "Epoch --> 10 Loss --> 9.761368751525879 Correct Pedictions --> 59913\n",
            "Training Accuracy --> 0.99855\n",
            "Epoch --> 15 Loss --> 9.599959373474121 Correct Pedictions --> 59934\n",
            "Training Accuracy --> 0.9989\n",
            "Epoch --> 20 Loss --> 9.211004257202148 Correct Pedictions --> 59932\n",
            "Training Accuracy --> 0.9988666666666667\n",
            "Epoch --> 25 Loss --> 4.684169292449951 Correct Pedictions --> 59962\n",
            "Training Accuracy --> 0.9993666666666666\n",
            "Epoch --> 30 Loss --> 8.321145057678223 Correct Pedictions --> 59947\n",
            "Training Accuracy --> 0.9991166666666667\n",
            "Epoch --> 35 Loss --> 3.5121378898620605 Correct Pedictions --> 59977\n",
            "Training Accuracy --> 0.9996166666666667\n",
            "Epoch --> 40 Loss --> 8.410188674926758 Correct Pedictions --> 59949\n",
            "Training Accuracy --> 0.99915\n",
            "Epoch --> 45 Loss --> 8.81149959564209 Correct Pedictions --> 59959\n",
            "Training Accuracy --> 0.9993166666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "f2feV0l1Nf8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "testing_loss = 0\n",
        "with torch.no_grad():\n",
        "    preds = []\n",
        "    for x, y in test_dataloader:\n",
        "        model.eval()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        pred = model(x)\n",
        "        loss = lossFN(pred, y)\n",
        "\n",
        "        predicted = pred.argmax(dim=1).cpu().numpy()\n",
        "        preds.extend(predicted)\n",
        "        labels = y.cpu().numpy()\n",
        "        correct_predictions += (predicted == labels).sum()\n",
        "        testing_loss+=loss\n",
        "\n",
        "print(f\"Loss --> {testing_loss}\", end = \" \")\n",
        "print(f\"Correct Pedictions --> {correct_predictions}\")\n",
        "print(f\"Testing Accuracy --> {correct_predictions/len(test_dataset)}\")\n",
        "print(classification_report(test_dataset.targets.cpu().numpy(),\n",
        "\tnp.array(preds), target_names=test_dataset.classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp_RdG2l1xMP",
        "outputId": "71b8fece-e68d-409a-f808-18819a58b909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss --> 40.65696716308594 Correct Pedictions --> 9931\n",
            "Testing Accuracy --> 0.9931\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    0 - zero       0.99      1.00      1.00       980\n",
            "     1 - one       0.99      1.00      1.00      1135\n",
            "     2 - two       0.99      0.99      0.99      1032\n",
            "   3 - three       0.99      0.99      0.99      1010\n",
            "    4 - four       0.99      0.99      0.99       982\n",
            "    5 - five       0.99      0.99      0.99       892\n",
            "     6 - six       1.00      0.99      0.99       958\n",
            "   7 - seven       1.00      0.99      0.99      1028\n",
            "   8 - eight       0.99      1.00      0.99       974\n",
            "    9 - nine       0.99      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}