{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JlTMJmz12Ca_"
      ],
      "authorship_tag": "ABX9TyPcdhbfJaSOVJlVgJS9K0nX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahausmani/deep_learning/blob/main/digit-recognition/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:**\n",
        "\n",
        "This is a from scratch implementation of a multi layer perceptron that classifies hand written digits. The architecture contains an nout layer with 784 (28x 28) neurons, 1 hidden layer with 16 neurons and output layer with 10 neurons corresponding to each of the nine digits.\n",
        "\n",
        "<img src=\"images/1.png\" style=\"width:650px;height:400px;\">\n",
        "<img src=\"images/2.png\" style=\"width:650px;height:400px;\">\n",
        "<img src=\"images/2.png\" style=\"width:650px;height:400px;\">"
      ],
      "metadata": {
        "id": "gVtYREiuuYJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "hDy1VTj1lA8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensor-sensor"
      ],
      "metadata": {
        "id": "5JwE7IbRQUqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Dc9yR20NgDXk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from tsensor import explain as exp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mahausmani/deep_learning.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQ5n4IgljD-",
        "outputId": "6f6cf0dc-3aef-4b9a-b0f6-bd9c8e7619f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deep_learning' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "uRfhoUfX56Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "lr = 0.01\n",
        "batck_size = 64\n",
        "m = len(X_train)"
      ],
      "metadata": {
        "id": "wmTZ5gir58jX"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "161jGCAtvzz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/deep_learning/digit-recognition/data/mnist_data.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE4c14mvpbiJ",
        "outputId": "85b6b94d-0eb3-4f78-eef2-e8e805feebf1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/deep_learning/digit-recognition/data/mnist_data.zip\n",
            "replace mnist_test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace mnist_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: mnist_train.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/mnist_train.csv\")\n",
        "test = pd.read_csv(\"/content/mnist_test.csv\")"
      ],
      "metadata": {
        "id": "K4kSJIUSrDUy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rename_columns(df):\n",
        "    cols = test.columns[1:]\n",
        "    renamed_cols = [i for i in range(1,785)]\n",
        "    d = {}\n",
        "    for index,i in enumerate(cols):\n",
        "        d[i] = renamed_cols[index]\n",
        "    df.rename(columns=d, inplace = True)\n"
      ],
      "metadata": {
        "id": "QDFmWNCtsZqT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rename_columns(train)\n",
        "rename_columns(test)"
      ],
      "metadata": {
        "id": "jHj2UF90vVeX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Dataset"
      ],
      "metadata": {
        "id": "zcwXKCob1TfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(train.iloc[:,1:])\n",
        "X_test = np.array(test.iloc[:,1:])\n",
        "Y_train = np.array(train.iloc[:,0])\n",
        "Y_test = np.array(test.iloc[:,0])"
      ],
      "metadata": {
        "id": "Lr3zsdyzwLHm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train2 = [[0] * 10 for i in range(len(Y_train))]\n",
        "for i in range(len(Y_train2)):\n",
        "    Y_train2[i][Y_train[i]] = 1\n",
        "Y_train = Y_train2"
      ],
      "metadata": {
        "id": "wSWsElIZeseG"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions\n"
      ],
      "metadata": {
        "id": "JlTMJmz12Ca_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "metadata": {
        "id": "8Ykdhih02Ek1"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(input_units, output_units):\n",
        "    weights = np.random.normal(loc=0.0, scale = np.sqrt(2/(input_units+output_units)), size = (output_units,input_units))\n",
        "    return weights\n",
        "\n",
        "def initialize_bias(output_units):\n",
        "    biases = np.zeros(output_units)\n",
        "    return biases"
      ],
      "metadata": {
        "id": "DNoycd5PILtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unvectorized implementation"
      ],
      "metadata": {
        "id": "wb8mZmGUH5N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(W1, W2, X):\n",
        "    z2 = np.dot(W1,X)\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(W2, a2)\n",
        "    a3 = sigmoid(z3)\n",
        "\n",
        "    return {\"a3\": a3, \"z3\":z3, \"a2\": a2, \"z2\": z2}\n",
        "\n",
        "def backward(x, z2, a2, z3, a3, y, w2):\n",
        "    da3 = y - a3                                                                           # [10 x 1] - [10 x 1] = [10 x 1]\n",
        "    dz3 = (1 - a3) * (a3)                                                                  # [10 x 1] * [10 x 1] = [10 x 1]\n",
        "    dw2 = a2                                                                               # [16 x 1]\n",
        "    dw2 = (da3 *  dz3).reshape(-1,1) @ dw2.reshape(-1,1).T                                 # [10 x 1] * [1 x 16] = [10 x 16]\n",
        "\n",
        "    da2 = w2                                                                               # [16  x 784]\n",
        "    dz2 = (1 - a2) * a2                                                                    # [16  x 1  ]\n",
        "    dw1 = x                                                                                # [784 x 1  ]\n",
        "    dw1 = ((w2.T @ (da3 * dz3).reshape(-1,1)) * dz2.reshape(-1,1)) * x.reshape(-1,1).T    # [16  x 10 ] * [10 x 1] * [16 x 1] * [1 x 784] = [16 x 784]\n",
        "    return dw1, dw2\n",
        ""
      ],
      "metadata": {
        "id": "qR9asnmdH4Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorized Implementation"
      ],
      "metadata": {
        "id": "pGrmbkWIIBth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_vectorized(W1, W2, X):\n",
        "    z2 = np.dot(W1,X)                                                                      # [512 x 784] @ [784 x 600000] = [512 x 6000000]\n",
        "    a2 = sigmoid(z2)                                                                       # [512 x 600000]\n",
        "\n",
        "    z3 = np.dot(W2, a2)                                                                    # [10 x 512] * [512 x 60000]\n",
        "    a3 = sigmoid(z3)                                                                       # [10 x 600000]\n",
        "\n",
        "    return {\"a3\": a3, \"z3\":z3, \"a2\": a2, \"z2\": z2}\n",
        "\n",
        "def backward_vectorized(x, z2, a2, z3, a3, y, w2):\n",
        "    da3 = y - a3                                                                           # [10 x 60000] - [10 x 60000] = [10 x 60000]\n",
        "    dz3 = (1 - a3) * (a3)                                                                  # [10 x 60000] * [10 x 60000] = [10 x 60000]\n",
        "    dw2 = a2                                                                               # [512 x 60000]\n",
        "    dw2 = (da3 *  dz3) @ dw2.T                                                             # [10 x 60000] * [60000 x 512] = [10 x 512]\n",
        "\n",
        "    da2 = w2                                                                               # [10  x 512]\n",
        "    dz2 = (1 - a2) * a2                                                                    # [512 x 60000]\n",
        "    dw1 = x                                                                                # [784 x 60000]\n",
        "    dw1 = ((w2.T @ (da3 * dz3)) * dz2) @ x.T                                                 # (([512 x 10 ] * [10 x 60000]) * [512 x 60000])* [60000 x 784] = [512 x 784]\n",
        "    return dw1, dw2\n"
      ],
      "metadata": {
        "id": "AT9GqtyvvfPX"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_weights(w1, w2,dw1, dw2):\n",
        "    w1 -= lr * dw1\n",
        "    w2 -= lr * dw2\n",
        "    return w1, w2"
      ],
      "metadata": {
        "id": "LNAYNJ-bGSa1"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function\n",
        "\n",
        "Loss function unvectorized"
      ],
      "metadata": {
        "id": "PImw5H-d4BQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(a,y):\n",
        "    mse = np.sum(np.sum((a - y) ** 2, axis = 0)/10)/a.shape[1]\n",
        "    return mse"
      ],
      "metadata": {
        "id": "H6Zm2q-p4Jjx"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function vectorized"
      ],
      "metadata": {
        "id": "ywvkDPFmIgTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss_vectorized(a,y):\n",
        "    mse = np.sum((a - y)**2)/len(a)\n",
        "    return mse"
      ],
      "metadata": {
        "id": "nkJIOIb7Iqjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop SGD"
      ],
      "metadata": {
        "id": "GlLfonlw517a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = initialize_weights(784,512)\n",
        "W2 = initialize_weights(512,10)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(len(X_train)):\n",
        "        image = X_train[i]                                           #\n",
        "        y = Y_train[i]\n",
        "        cache = forward(W1, W2, image)\n",
        "        z2 = cache[\"z2\"]\n",
        "        a2 = cache[\"a2\"]\n",
        "        z3 = cache[\"z3\"]\n",
        "        a3 = cache[\"a3\"]\n",
        "        loss = calculate_loss(a3,y)\n",
        "        dw1, dw2 = backward(image, z2, a2, z3, a3, y, W2)\n",
        "        update_weights(W1, W2, dw1, dw2)\n",
        "        if i % 5000 == 0:\n",
        "            print(f\"Epoch: {epoch}, Loss = {loss}\")\n"
      ],
      "metadata": {
        "id": "vIVDYJCM54lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop Vectorized"
      ],
      "metadata": {
        "id": "Jo9epB2UHjCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = initialize_weights(784,512)\n",
        "W2 = initialize_weights(512,10)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    image = X_train                              # [60000 x 784]\n",
        "    y = np.array(Y_train)                        # [60000 x 10]\n",
        "    y = y.T                                      # [10 x 600000]\n",
        "    image = image.T                              # [784 x 60000]\n",
        "    cache = forward_vectorized(W1, W2, image)\n",
        "    z2 = cache[\"z2\"]\n",
        "    a2 = cache[\"a2\"]\n",
        "    z3 = cache[\"z3\"]\n",
        "    a3 = cache[\"a3\"]\n",
        "    loss = calculate_loss_vectorized(a3,y)\n",
        "    dw1, dw2 = backward_vectorized(image, z2, a2, z3, a3, y, W2)\n",
        "    W1, W2 = update_weights(W1, W2, dw1, dw2)\n",
        "    print(f\"Epoch: {epoch}, Loss = {loss}\")\n"
      ],
      "metadata": {
        "id": "tIwYDwBDrIwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tsensor import explain as exp\n",
        "a = np.array([[0,1],[0,1],[0,1]])\n",
        "b = np.array([[2],[1]])\n",
        "with exp() as c:\n",
        "    c = a @ b"
      ],
      "metadata": {
        "id": "Ew3RUbvBQFw8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}