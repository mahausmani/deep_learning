{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLauLUWZWEb797yCotnJmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahausmani/deep_learning/blob/main/digit-recognition/mlp_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "wEZZK-WaEx30"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Only0hU4NAE",
        "outputId": "9f515dc0-58be-45d9-e5a1-3f2a6622797e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.2.1+cu121\n",
            "No GPU found, using CPU instead.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print('Using PyTorch version:', torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "    print('Using GPU, device name:', torch.cuda.get_device_name(0))\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print('No GPU found, using CPU instead.')\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "gI0p14Qi5q3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "data_dir = \"/content/train\""
      ],
      "metadata": {
        "id": "M1IQVVxM5sgQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data\n"
      ],
      "metadata": {
        "id": "1t-4G_bz5UUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch has two classes from torch.utils.data to work with data:\n",
        "\n",
        "Dataset which represents the actual data items, such as images or pieces of text, and their labels\n",
        "\n",
        "DataLoader which is used for processing the dataset in batches in an efficient manner.\n",
        "\n",
        "The dataloader randomly selects batches from the training dataset when you loop over the data loader. In the for loop below, each time a new tensor of size [32, 1, 28, 28] is loaded"
      ],
      "metadata": {
        "id": "kGmLC5mZE4Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(data_dir, train = True, download = True, transform = ToTensor())\n",
        "test_dataset = datasets.MNIST(data_dir, train = False, download = True, transform = ToTensor())\n",
        "\n",
        "train_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "W0Mr88xW5mfu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data, target in train_dataloader:\n",
        "    print(target.shape, data.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CElju_n39bFk",
        "outputId": "39272cad-310d-4dd7-d7c5-3888cd7fc78b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32]) torch.Size([32, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example"
      ],
      "metadata": {
        "id": "vGQMYhDuEOx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below gives example of how to use nn.Flatten().\n",
        "The optional parameters, give the start and end positions"
      ],
      "metadata": {
        "id": "jlKoiQ-TCxaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With default parameters\n",
        "input = torch.randn(32, 1, 5, 5)\n",
        "m = nn.Flatten()\n",
        "output = m(input)\n",
        "print(output.size())  # torch.Size([32, 25])\n",
        "\n",
        "# With non-default parameters\n",
        "m = nn.Flatten(0, 2)\n",
        "output = m(input)\n",
        "print(output.size())  # torch.Size([160, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tqZJijO9hxc",
        "outputId": "c2059863-e463-46e3-d4be-bd716e7de830"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 25])\n",
            "torch.Size([160, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "W1A75K79ERaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        output = self.layers(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "qLmD_jqoB07E"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP().to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKUJdCXkD3aC",
        "outputId": "52bafd54-f18a-46ce-bfa2-4911abed26df"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (layers): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "gV4taFvnE7za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "Fwbl4WAdE_je"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader, model, criterion, optimizer):\n",
        "    total_loss = 0\n",
        "    for data, target in data_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model.forward(data)\n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return total_loss/len(data_loader)"
      ],
      "metadata": {
        "id": "tYSL8GZdFhmg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    loss = train(train_dataloader, model, criterion, optimizer)\n",
        "    print(f\"Epoch--> {i}    Loss--> {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWigXvvBG-DX",
        "outputId": "aebed8c4-34c2-422b-e1fd-1443da69d5ea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch--> 0    Loss--> 2.3071506023406982\n",
            "Epoch--> 1    Loss--> 2.307149887084961\n",
            "Epoch--> 2    Loss--> 2.3071494102478027\n",
            "Epoch--> 3    Loss--> 2.3071482181549072\n",
            "Epoch--> 4    Loss--> 2.3071484565734863\n",
            "Epoch--> 5    Loss--> 2.307147741317749\n",
            "Epoch--> 6    Loss--> 2.3071482181549072\n",
            "Epoch--> 7    Loss--> 2.3071484565734863\n",
            "Epoch--> 8    Loss--> 2.3071467876434326\n",
            "Epoch--> 9    Loss--> 2.307149887084961\n",
            "Epoch--> 10    Loss--> 2.3071510791778564\n",
            "Epoch--> 11    Loss--> 2.307149887084961\n",
            "Epoch--> 12    Loss--> 2.3071513175964355\n",
            "Epoch--> 13    Loss--> 2.307149648666382\n",
            "Epoch--> 14    Loss--> 2.307147741317749\n",
            "Epoch--> 15    Loss--> 2.3071467876434326\n",
            "Epoch--> 16    Loss--> 2.3071513175964355\n",
            "Epoch--> 17    Loss--> 2.3071491718292236\n",
            "Epoch--> 18    Loss--> 2.3071506023406982\n",
            "Epoch--> 19    Loss--> 2.307147741317749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "OY8dF-txLEWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_dataloader, model, criterion, optimizer):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_dataloader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output =  model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss\n",
        "    print(f\"Average loss: {total_loss/len(test_dataloader):>7f}\")\n",
        "    return total_loss/len(test_dataloader)\n"
      ],
      "metadata": {
        "id": "i_LKRCDLHiEH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_dataloader, model, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5CUx6n9Kt0T",
        "outputId": "cee305f0-a733-467f-d27d-9c42aba7fbcd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.306066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3061)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "qNkeOo7dLHeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image, output, model):\n",
        "    with torch.no_grad():\n",
        "        output1 = model(image)\n",
        "    print(np.argmax(np.array(output1)), output)\n",
        "\n",
        "input, output = train_dataloader.dataset[0]\n",
        "predict(input.reshape(1,784), output, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfAz4ui8LCyw",
        "outputId": "17a8694a-dd31-47ee-eac5-8a2e4ced4dc4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 5\n"
          ]
        }
      ]
    }
  ]
}